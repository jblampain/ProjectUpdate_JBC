{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "## Project: Write an Algorithm for Landmark Classification\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The project folder has the following structure:\n",
    "\n",
    "* In the main directory you have this notebook, `cnn_from_scratch.ipynb`, that contains the instruction and some questions you will have to answer. Follow this notebook and complete the required sections in order.\n",
    "\n",
    "* In the `src/` directory you have several source files. As instructed in this notebook, you will open and complete those files, then come back to this notebook to execute some tests that will verify what you have done. While these tests don't guarantee that your work is bug-free, they will help you finding the most obvious problems so you will be able to proceed to the next step with confidence.\n",
    "\n",
    "* Sometimes you will need to restart the notebook. If you do so, remember to execute also the cells containing the code you have already completed starting from the top, before you move on.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    "> <img src=\"static_images/icons/noun-info-2558213.png\" alt=\"?\" style=\"width:25px\"/> Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut.  Markdown cells can be edited by double-clicking the cell to enter edit mode.\n",
    "\n",
    "The rubric contains _optional_ \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. If you decide to pursue the \"Stand Out Suggestions\", you should include the code in this Jupyter notebook.\n",
    "\n",
    "### Designing and training a CNN from scratch\n",
    "\n",
    "In this notebook, you will create a CNN that classifies landmarks.  You must create your CNN _from scratch_ (so, you can't use transfer learning _yet_!), and you must attain a test accuracy of at least 50%.\n",
    "\n",
    "Although 50% may seem low at first glance, it seems more reasonable after realizing how difficult of a problem this is. Many times, an image that is taken at a landmark captures a fairly mundane image of an animal or plant, like in the following picture.\n",
    "\n",
    "<img src=\"static_images/train/00.Haleakala_National_Park/084c2aa50d0a9249.jpg\" alt=\"Bird in Haleakalā National Park\" style=\"width: 400px;\"/>\n",
    "\n",
    "Just by looking at that image alone, would you have been able to guess that it was taken at the Haleakalā National Park in Hawaii?\n",
    "\n",
    "An accuracy of 50% is significantly better than random guessing, which would provide an accuracy of just 2% (100% / 50 classes). In Step 2 of this notebook, you will have the opportunity to greatly improve accuracy by using transfer learning to create a CNN.\n",
    "\n",
    "Experiment with different architectures, hyperparameters, training strategies, and trust your intuition.  And, of course, have fun!\n",
    "\n",
    "---\n",
    "## <img src=\"static_images/icons/noun-advance-2109145.png\" alt=\">\" style=\"width:50px\"/> Step 0: Setting up\n",
    "\n",
    "The following cells make sure that your environment is setup correctly, download the data if you don't have it already, and also check that your GPU is available and ready to go. You have to execute them every time you restart your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2371959977.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install requirements.txt\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install requirements.txt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is F4D6-C7FC\n",
      "\n",
      " Directory of C:\\Users\\jblam\\Downloads\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\n",
      "\n",
      "31/03/2024  07:43 PM    <DIR>          .\n",
      "31/03/2024  07:43 PM    <DIR>          ..\n",
      "31/03/2024  07:43 PM    <DIR>          .ipynb_checkpoints\n",
      "31/03/2024  07:26 PM    <DIR>          .pytest_cache\n",
      "31/03/2024  07:36 PM            63,655 app.ipynb\n",
      "31/03/2024  07:07 PM    <DIR>          checkpoints\n",
      "31/03/2024  07:36 PM            46,180 cnn_from_scratch.ipynb\n",
      "31/03/2024  07:43 PM            31,245 cnn_from_scratch_Copy.ipynb\n",
      "31/03/2024  06:59 PM             2,701 landmark.zip\n",
      "31/03/2024  07:05 PM    <DIR>          landmark_images\n",
      "31/03/2024  07:36 PM             1,462 mean_and_std.pt\n",
      "31/03/2024  07:36 PM             5,345 README.md\n",
      "31/03/2024  07:36 PM               234 requirements.txt\n",
      "31/03/2024  07:25 PM    <DIR>          src\n",
      "31/03/2024  06:59 PM    <DIR>          static_images\n",
      "31/03/2024  07:36 PM            45,233 transfer_learning.ipynb\n",
      "               8 File(s)        196,055 bytes\n",
      "               8 Dir(s)  340,452,663,296 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'dir_zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mshutil\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m shutil\u001b[39m.\u001b[39;49mmake_archive(\u001b[39m'\u001b[39;49m\u001b[39mlan\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mzip\u001b[39;49m\u001b[39m'\u001b[39;49m, root_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdir_zip\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\jblampain\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\shutil.py:1183\u001b[0m, in \u001b[0;36mmake_archive\u001b[1;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[0;32m   1181\u001b[0m save_cwd \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m \u001b[39mif\u001b[39;00m root_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1183\u001b[0m     stmd \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(root_dir)\u001b[39m.\u001b[39mst_mode\n\u001b[0;32m   1184\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stat\u001b[39m.\u001b[39mS_ISDIR(stmd):\n\u001b[0;32m   1185\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotADirectoryError\u001b[39;00m(errno\u001b[39m.\u001b[39mENOTDIR, \u001b[39m'\u001b[39m\u001b[39mNot a directory\u001b[39m\u001b[39m'\u001b[39m, root_dir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'dir_zip'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive('lan', format='zip', root_dir='dir_zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Install requirements\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install -r requirements.txt | grep -v \u001b[39m\u001b[39m\"\u001b[39m\u001b[39malready satisfied\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[39m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[39mif\u001b[39;00m info\u001b[39m.\u001b[39mpydev_state \u001b[39m==\u001b[39m STATE_SUSPEND:\n\u001b[1;32m--> 988\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_wait_suspend(thread, frame, event, arg)\n\u001b[0;32m    989\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrace_dispatch\n\u001b[0;32m    990\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_wait_suspend\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mdo_wait_suspend(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Install requirements\n",
    "!pip install -r requirements.txt | grep -v \"already satisfied\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important! After you have ran pip install, please restart the kernel using the **Kernel** menu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'location' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(location)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'location' is not defined"
     ]
    }
   ],
   "source": [
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU *NOT* available. Will use CPU (slow)\n",
      "Dataset already downloaded. If you need to re-download, please delete the directory landmark_images\n",
      "Reusing cached mean and std\n"
     ]
    }
   ],
   "source": [
    "from src.helpers import setup_env\n",
    "\n",
    "# If running locally, this will download dataset (make sure you have at \n",
    "# least 2 Gb of space on your hard drive)\n",
    "setup_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <img src=\"static_images/icons/noun-advance-2109145.png\" alt=\">\" style=\"width:50px\"/> Step 1: Data\n",
    "\n",
    "In this and the following steps we are going to complete some code, and then execute some tests to make sure the code works as intended. \n",
    "\n",
    "Open the file `src/data.py`. It contains a function called `get_data_loaders`. Read the function and complete all the parts marked by `YOUR CODE HERE`. Once you have finished, test that your implementation is correct by executing the following cell (see below for what to do if a test fails):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytest\n",
      "  Downloading pytest-8.1.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting iniconfig (from pytest)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\jblampain\\appdata\\roaming\\python\\python312\\site-packages (from pytest) (23.2)\n",
      "Collecting pluggy<2.0,>=1.4 (from pytest)\n",
      "  Downloading pluggy-1.4.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jblampain\\appdata\\roaming\\python\\python312\\site-packages (from pytest) (0.4.6)\n",
      "Downloading pytest-8.1.1-py3-none-any.whl (337 kB)\n",
      "   ---------------------------------------- 0.0/337.4 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 30.7/337.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 143.4/337.4 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 327.7/337.4 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 337.4/337.4 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading pluggy-1.4.0-py3-none-any.whl (20 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Installing collected packages: pluggy, iniconfig, pytest\n",
      "Successfully installed iniconfig-2.0.0 pluggy-1.4.0 pytest-8.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts py.test.exe and pytest.exe are installed in 'c:\\Users\\jblampain\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.7, pytest-7.4.0, pluggy-1.0.0 -- C:\\Users\\jblam\\anaconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\jblam\\Downloads\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\n",
      "plugins: anyio-4.2.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items / 1 deselected / 3 selected\n",
      "\n",
      "src/data.py::test_data_loaders_keys \u001b[32mPASSED\u001b[0m\u001b[32m                               [ 33%]\u001b[0m\n",
      "src/data.py::test_data_loaders_output_type \u001b[32mPASSED\u001b[0m\u001b[32m                        [ 66%]\u001b[0m\n",
      "src/data.py::test_data_loaders_output_shape \u001b[32mPASSED\u001b[0m\u001b[32m                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m3 passed\u001b[0m, \u001b[33m1 deselected\u001b[0m\u001b[32m in 2.79s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -vv src/data.py -k data_loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see something like:\n",
    "```\n",
    "src/data.py::test_data_loaders_keys PASSED                               [ 33%]\n",
    "src/data.py::test_data_loaders_output_type PASSED                        [ 66%]\n",
    "src/data.py::test_data_loaders_output_shape PASSED                       [100%]\n",
    "\n",
    "======================= 3 passed, 1 deselected in 1.81s ========================\n",
    "```\n",
    "If all the tests are `PASSED`, you can move to the next section.\n",
    "\n",
    "> <img src=\"static_images/icons/noun-info-2558213.png\" alt=\"?\" style=\"width:25px\"/> **What to do if tests fail**\n",
    "When a test fails, `pytest` will mark it as `FAILED` as opposed to `PASSED`, and will print a lot of useful output, including a message that should tell you what the problem is. For example, this is the output of a failed test:\n",
    "> ```\n",
    ">    def test_data_loaders_keys(data_loaders):\n",
    ">    \n",
    ">       assert set(data_loaders.keys()) == {\"train\", \"valid\", \"test\"}\n",
    "E       AssertionError: assert {'tes', 'train', 'valid'} == {'test', 'train', 'valid'}\n",
    "E         Extra items in the left set:\n",
    "E         'tes'\n",
    "E         Full diff:\n",
    "E         - {'test', 'train', 'valid'}\n",
    "E         + {'tes', 'train', 'valid'}\n",
    "E         ?                          +++++++\n",
    ">\n",
    "> src/data.py:171: AssertionError\n",
    "-------------- Captured stdout setup ----------------------------------------------\n",
    "Reusing cached mean and std for landmark_images\n",
    "Dataset mean: tensor([0.4638, 0.4725, 0.4687]), std: tensor([0.2699, 0.2706, 0.3018])\n",
    "=========== short test summary info ===============================================\n",
    "FAILED src/data.py::test_data_loaders_keys - AssertionError: The keys of the data_loaders dictionary should be train, valid and test\n",
    "> ``` \n",
    "> In the `short test summary info` you can see a short description of the problem. In this case, the dictionary we are returning has the wrong keys. Going above a little, you can see that the test expects `{'test', 'train', 'valid'}` while we are returning `{'tes', 'train', 'valid'}` (there is a missing `t`). So we can go back to our function, fix that problem and test again.\n",
    "> \n",
    "> In other cases, you might get an error like:\n",
    "> ```\n",
    "    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n",
    "        if self.padding_mode != 'zeros':\n",
    "            return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
    "                            weight, bias, self.stride,\n",
    "                            _pair(0), self.dilation, self.groups)\n",
    "        return F.conv2d(input, weight, bias, self.stride,\n",
    ">                       self.padding, self.dilation, self.groups)\n",
    "E       RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\n",
    ">\n",
    "> ../../../../miniconda3/envs/udacity_starter/lib/python3.7/site-packages/torch/nn/modules/conv.py:440: RuntimeError\n",
    "> ```\n",
    "> Looking at the stack trace you should be able to understand what it is going on. In this case, we forgot to add a `.cuda()` to some tensor. For example, the model is on the GPU, but the data aren't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"static_images/icons/noun-question-mark-869751.png\" alt=\"?\" style=\"width:25px\"/> **Question:** Describe your chosen procedure for preprocessing the data. \n",
    "- How does your code resize the images (by cropping, stretching, etc)?  What size did you pick for the input tensor, and why?\n",
    "- Did you decide to augment the dataset?  If so, how (through translations, flips, rotations, etc)?  If not, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"static_images/icons/noun-answer-3361020.png\" alt=\">\" style=\"width:25px\"/> **Answer**: My code first resizes the image to 256 and then crops to 224. I picked 224 as the input size because it is the recommended input size for using pytorch's pre-trained models. I did decide to augment the dataset via RandAugment, a typical set of augmentations for natural images. I added this augmentation with the goal of improving my model's robustness, thus improving test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Training Data\n",
    "\n",
    "Go back to `src/data.py` and complete the function `visualize_one_batch` in all places with the `YOUR CODE HERE` marker. After you're done, execute the following cell and make sure the test `src/data.py::test_visualize_one_batch` is `PASSED`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.7, pytest-7.4.0, pluggy-1.0.0 -- C:\\Users\\jblam\\anaconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\jblam\\Downloads\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\n",
      "plugins: anyio-4.2.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items / 3 deselected / 1 selected\n",
      "\n",
      "src/data.py::test_visualize_one_batch \u001b[32mPASSED\u001b[0m\u001b[32m                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m3 deselected\u001b[0m\u001b[32m in 3.06s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -vv src/data.py -k visualize_one_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the code we just completed to get a batch of images from your train data loader and look at them.\n",
    "\n",
    "Visualizing the output of your data loader is a great way to ensure that your data loading and preprocessing (including transforms such as rotations, translations, color transforms...) are working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing cached mean and std\n",
      "Dataset mean: tensor([0.4638, 0.4725, 0.4687]), std: tensor([0.2697, 0.2706, 0.3017])\n",
      "Reusing cached mean and std\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from src.data import visualize_one_batch, get_data_loaders\n",
    "\n",
    "# use get_data_loaders to get the data_loaders dictionary. Use a batch_size\n",
    "# of 5, a validation size of 0.01 and num_workers=-1 (all CPUs) - # I changed numn workers to 0\n",
    "\n",
    "data_loaders = get_data_loaders(batch_size=5, valid_size=0.01, num_workers=0)\n",
    "\n",
    "visualize_one_batch(data_loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <img src=\"static_images/icons/noun-advance-2109145.png\" alt=\">\" style=\"width:50px\"/> Step 2: Define model\n",
    "\n",
    "Open `src/model.py` and complete the `MyModel` class filling in all the `YOUR CODE HERE` sections. After you're done, execute the following test and make sure it passes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=50176, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=50, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes: int = 50,dropout: float = 0.7) -> None:\n",
    "        super(MyModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1), #224x224x3 -> 224x224x16 -> maxpool 112x112x16\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), #112x112x16 -> 112x112x32 -> maxpool 56x56x32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), #56x56x32 -> 56x56x64 -> maxpool 28x28x64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 28 * 28, 512),  # Adjust input size based on your image dimensions\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),  # Add dropout for regularization\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = MyModel(num_classes=50)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 224, 224]             448\n",
      "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
      "              ReLU-3         [-1, 16, 224, 224]               0\n",
      "         MaxPool2d-4         [-1, 16, 112, 112]               0\n",
      "            Conv2d-5         [-1, 32, 112, 112]           4,640\n",
      "       BatchNorm2d-6         [-1, 32, 112, 112]              64\n",
      "              ReLU-7         [-1, 32, 112, 112]               0\n",
      "         MaxPool2d-8           [-1, 32, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]          18,496\n",
      "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
      "             ReLU-11           [-1, 64, 56, 56]               0\n",
      "        MaxPool2d-12           [-1, 64, 28, 28]               0\n",
      "          Flatten-13                [-1, 50176]               0\n",
      "           Linear-14                  [-1, 512]      25,690,624\n",
      "             ReLU-15                  [-1, 512]               0\n",
      "          Dropout-16                  [-1, 512]               0\n",
      "           Linear-17                   [-1, 50]          25,650\n",
      "================================================================\n",
      "Total params: 25,740,082\n",
      "Trainable params: 25,740,082\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 35.23\n",
      "Params size (MB): 98.19\n",
      "Estimated Total Size (MB): 134.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\jblam\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.7, pytest-7.4.0, pluggy-1.0.0 -- C:\\Users\\jblam\\anaconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\jblam\\Downloads\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\n",
      "plugins: anyio-4.2.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "src/model.py::test_model_construction \u001b[32mPASSED\u001b[0m\u001b[32m                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 7.43s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -vv src/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"static_images/icons/noun-question-mark-869751.png\" alt=\"?\" style=\"width:25px\"/> **Question**: Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"static_images/icons/noun-answer-3361020.png\" alt=\">\" style=\"width:25px\"/> __Answer:__ I decided to use 5 convolutional layers so that my model could be sufficiently expressive. I used dropout layers to reduce my model's tendency to overfit the training data. I made my model output a 50-dimensional vector to match with the 50 available landmark classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <img src=\"static_images/icons/noun-advance-2109145.png\" alt=\">\" style=\"width:50px\"/> Step 3: define loss and optimizer\n",
    "\n",
    "Open `src/optimization.py` and complete the `get_loss` function, then execute the test and make sure it passes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.7, pytest-7.4.0, pluggy-1.0.0 -- C:\\Users\\jblam\\anaconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\jblam\\Downloads\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\n",
      "plugins: anyio-4.2.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 7 items / 6 deselected / 1 selected\n",
      "\n",
      "src/optimization.py::test_get_loss \u001b[32mPASSED\u001b[0m\u001b[32m                                [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m6 deselected\u001b[0m\u001b[32m in 1.44s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -vv src/optimization.py -k get_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, in the same file, complete the `get_optimizer` function then execute its tests, and make sure they all pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.7, pytest-7.4.0, pluggy-1.0.0 -- C:\\Users\\jblam\\anaconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\jblam\\Downloads\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\n",
      "plugins: anyio-4.2.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 7 items / 1 deselected / 6 selected\n",
      "\n",
      "src/optimization.py::test_get_optimizer_type \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 16%]\u001b[0m\n",
      "src/optimization.py::test_get_optimizer_is_linked_with_model \u001b[32mPASSED\u001b[0m\u001b[32m      [ 33%]\u001b[0m\n",
      "src/optimization.py::test_get_optimizer_returns_adam \u001b[32mPASSED\u001b[0m\u001b[32m              [ 50%]\u001b[0m\n",
      "src/optimization.py::test_get_optimizer_sets_learning_rate \u001b[32mPASSED\u001b[0m\u001b[32m        [ 66%]\u001b[0m\n",
      "src/optimization.py::test_get_optimizer_sets_momentum \u001b[32mPASSED\u001b[0m\u001b[32m             [ 83%]\u001b[0m\n",
      "src/optimization.py::test_get_optimizer_sets_weight_decat \u001b[32mPASSED\u001b[0m\u001b[32m         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m6 passed\u001b[0m, \u001b[33m1 deselected\u001b[0m\u001b[32m in 2.06s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -vv src/optimization.py -k get_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <img src=\"static_images/icons/noun-advance-2109145.png\" alt=\">\" style=\"width:50px\"/> Step 4: Train and Validate the Model\n",
    "\n",
    "> <img src=\"static_images/icons/noun-info-2558213.png\" alt=\"?\" style=\"width:25px\"/> Testing ML code is notoriously difficult. The tests in this section merely exercise the functions you are completing, so it will help you catching glaring problems but it won't guarantee that your training code is bug-free. If you see that your loss is not decreasing, for example, that's a sign of a bug or of a flawed model design. Use your judgement.\n",
    "\n",
    "Open `src/train.py` and complete the `train_one_epoch` function, then run the tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting livelossplot\n",
      "  Downloading livelossplot-0.5.5-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from livelossplot) (3.8.0)\n",
      "Requirement already satisfied: bokeh in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from livelossplot) (3.3.4)\n",
      "Requirement already satisfied: Jinja2>=2.9 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (3.1.3)\n",
      "Requirement already satisfied: contourpy>=1 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (1.26.4)\n",
      "Requirement already satisfied: packaging>=16.8 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (23.1)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (2.1.4)\n",
      "Requirement already satisfied: pillow>=7.1.0 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (10.2.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (6.0.1)\n",
      "Requirement already satisfied: tornado>=5.1 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (6.3.3)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from bokeh->livelossplot) (2022.9.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jblam\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
      "Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: livelossplot\n",
      "Successfully installed livelossplot-0.5.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.7, pytest-7.4.0, pluggy-1.0.0 -- C:\\Users\\jblam\\anaconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\jblam\\Downloads\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\n",
      "plugins: anyio-4.2.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items / 3 deselected / 1 selected\n",
      "\n",
      "src/train.py::test_train_one_epoch \u001b[32mPASSED\u001b[0m\u001b[32m                                [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m====================== \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m3 deselected\u001b[0m\u001b[32m in 17.67s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -vv src/train.py -k train_one_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now complete the `valid` function, then run the tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.7, pytest-7.4.0, pluggy-1.0.0 -- C:\\Users\\jblam\\anaconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\jblam\\Downloads\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\n",
      "plugins: anyio-4.2.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items / 3 deselected / 1 selected\n",
      "\n",
      "src/train.py::test_valid_one_epoch \u001b[32mPASSED\u001b[0m\u001b[32m                                [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m3 deselected\u001b[0m\u001b[32m in 8.13s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -vv src/train.py -k valid_one_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now complete the `optimize` function, then run the tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.7, pytest-7.4.0, pluggy-1.0.0 -- C:\\Users\\jblam\\anaconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\jblam\\Downloads\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\n",
      "plugins: anyio-4.2.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items / 3 deselected / 1 selected\n",
      "\n",
      "src/train.py::test_optimize \u001b[32mPASSED\u001b[0m\u001b[32m                                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m============================== warnings summary ===============================\u001b[0m\n",
      "src/train.py::test_optimize\n",
      "  C:\\Users\\jblam\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "    warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m================= \u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m3 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 14.23s\u001b[0m\u001b[33m =================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -vv src/train.py -k optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, complete the `test` function then run the tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "len(self.samples) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m( class_names)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print( class_names)\n",
    "\n",
    "#output\n",
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.7, pytest-7.4.0, pluggy-1.0.0 -- C:\\Users\\jblam\\anaconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\jblam\\Downloads\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\n",
      "plugins: anyio-4.2.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items / 3 deselected / 1 selected\n",
      "\n",
      "src/train.py::test_one_epoch_test \u001b[31mFAILED\u001b[0m\u001b[31m                                 [100%]\u001b[0m\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_____________________________ test_one_epoch_test _____________________________\u001b[0m\n",
      "\n",
      "data_loaders = {'test': <torch.utils.data.dataloader.DataLoader object at 0x0000021DD4B86250>, 'train': <torch.utils.data.dataloader.DataLoader object at 0x0000021DD4B4DAD0>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x0000021DD2829250>}\n",
      "optim_objects = (MyModel(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1):...: False\n",
      "    foreach: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0.5\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      "))\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_one_epoch_test\u001b[39;49;00m(data_loaders, optim_objects):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        model, loss, optimizer = optim_objects\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       tv = one_epoch_test(data_loaders[\u001b[33m\"\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], model, loss)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31msrc\\train.py\u001b[0m:263: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31msrc\\train.py\u001b[0m:175: in one_epoch_test\n",
      "    \u001b[94mfor\u001b[39;49;00m batch_idx, (data, target) \u001b[95min\u001b[39;49;00m tqdm(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m..\\..\\..\\anaconda3\\Lib\\site-packages\\tqdm\\std.py\u001b[0m:1178: in __iter__\n",
      "    \u001b[94mfor\u001b[39;49;00m obj \u001b[95min\u001b[39;49;00m iterable:\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m..\\..\\..\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m:631: in __next__\n",
      "    data = \u001b[96mself\u001b[39;49;00m._next_data()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m..\\..\\..\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m:675: in _next_data\n",
      "    data = \u001b[96mself\u001b[39;49;00m._dataset_fetcher.fetch(index)  \u001b[90m# may raise StopIteration\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m..\\..\\..\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m:51: in fetch\n",
      "    data = [\u001b[96mself\u001b[39;49;00m.dataset[idx] \u001b[94mfor\u001b[39;49;00m idx \u001b[95min\u001b[39;49;00m possibly_batched_index]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m..\\..\\..\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m:51: in <listcomp>\n",
      "    data = [\u001b[96mself\u001b[39;49;00m.dataset[idx] \u001b[94mfor\u001b[39;49;00m idx \u001b[95min\u001b[39;49;00m possibly_batched_index]\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = Dataset ImageFolder\n",
      "    Number of datapoints: 1250\n",
      "    Root location: landmark_images\\test\n",
      "    StandardTransform\n",
      "Trans...or()\n",
      "               Normalize(mean=tensor([0.4638, 0.4725, 0.4687]), std=tensor([0.2697, 0.2706, 0.3017]))\n",
      "           )\n",
      "index = tensor(3830)\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__getitem__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, index: \u001b[96mint\u001b[39;49;00m) -> Tuple[Any, Any]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m        index (int): Index\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns:\u001b[39;49;00m\n",
      "    \u001b[33m        tuple: (sample, target) where target is class_index of the target class.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       path, target = \u001b[96mself\u001b[39;49;00m.samples[index]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       IndexError: list index out of range\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m..\\..\\..\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m:228: IndexError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "Reusing cached mean and std\n",
      "Dataset mean: tensor([0.4638, 0.4725, 0.4687]), std: tensor([0.2697, 0.2706, 0.3017])\n",
      "Loss function: <function get_loss at 0x0000021DD076BEC0>\n",
      "---------------------------- Captured stderr call -----------------------------\n",
      "\n",
      "Testing:   0%|                                            | 0/2 [00:00<?, ?it/s]\n",
      "Testing:   0%|                                            | 0/2 [00:00<?, ?it/s]\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m src/train.py::\u001b[1mtest_one_epoch_test\u001b[0m - IndexError: list index out of range\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m3 deselected\u001b[0m\u001b[31m in 3.44s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -vv src/train.py -k one_epoch_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <img src=\"static_images/icons/noun-advance-2109145.png\" alt=\">\" style=\"width:50px\"/> Step 5: Putting everything together\n",
    "\n",
    "Allright, good job getting here! Now it's time to see if all our hard work pays off. In the following cell we will train your model and validate it against the validation set.\n",
    "\n",
    "Let's start by defining a few hyperparameters. Feel free to experiment with different values and try to optimize your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32        # size of the minibatch for stochastic gradient descent (or Adam)\n",
    "valid_size = 0.2       # fraction of the training data to reserve for validation\n",
    "num_epochs = 50        # number of epochs for training\n",
    "num_classes = 50       # number of classes. Do not change this\n",
    "dropout = 0.4          # dropout for our model\n",
    "learning_rate = 0.001  # Learning rate for SGD (or Adam)\n",
    "opt = 'sgd'            # optimizer. 'sgd' or 'adam'\n",
    "weight_decay = 0.0     # regularization. Increase this to combat overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: <function get_loss at 0x00000203F35B4EA0>\n",
      "Reusing cached mean and std\n",
      "Dataset mean: tensor([0.4638, 0.4725, 0.4687]), std: tensor([0.2697, 0.2706, 0.3017])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jblam\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "Training: 100%|███████████████████████████████| 125/125 [01:57<00:00,  1.06it/s]\n",
      "Validating: 100%|███████████████████████████████| 32/32 [00:15<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 3.870422 \tValidation Loss: 3.747796\n",
      "New minimum validation loss: 3.747796. Saving model ...\n"
     ]
    }
   ],
   "source": [
    "from src.data import get_data_loaders\n",
    "from src.train import optimize\n",
    "from src.optimization import get_optimizer, get_loss\n",
    "from src.model import MyModel\n",
    "\n",
    "# get the data loaders using batch_size and valid_size defined in the previous\n",
    "# cell\n",
    "# HINT: do NOT copy/paste the values. Use the variables instead\n",
    "\n",
    "data_loaders = get_data_loaders(batch_size, valid_size) # YOUR CODE HERE\n",
    "\n",
    "# instance model MyModel with num_classes and drouput defined in the previous\n",
    "# cell\n",
    "model =  MyModel(num_classes,dropout) # YOUR CODE HERE\n",
    "\n",
    "# Get the optimizer using get_optimizer and the model you just created, the learning rate,\n",
    "# the optimizer and the weight decay specified in the previous cell\n",
    "optimizer =  get_optimizer(model,opt,learning_rate,weight_decay) # YOUR CODE HERE\n",
    "\n",
    "# Get the loss using get_loss\n",
    "loss = get_loss() # YOUR CODE HERE\n",
    "\n",
    "optimize(\n",
    "    data_loaders,\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    n_epochs=num_epochs,\n",
    "    save_path=\"checkpoints/best_val_loss.pt\",\n",
    "    interactive_tracking=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <img src=\"static_images/icons/noun-advance-2109145.png\" alt=\">\" style=\"width:50px\"/> Step 6: testing against the Test Set\n",
    "\n",
    "> <img src=\"static_images/icons/noun-info-2558213.png\" alt=\"?\" style=\"width:25px\"/> only run this *after* you have completed hyperpameter optimization. Do not optimize hyperparameters by looking at the results on the test set, or you might overfit on the test set (bad, bad, bad)\n",
    "\n",
    "Run the code cell below to try out your model on the test dataset of landmark images. Ensure that your test accuracy is greater than 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "from src.train import one_epoch_test\n",
    "from src.model import MyModel\n",
    "import torch\n",
    "\n",
    "model = MyModel(num_classes=num_classes, dropout=dropout)\n",
    "\n",
    "# YOUR CODE HERE: load the weights in 'checkpoints/best_val_loss.pt'\n",
    "model.load_state_dict(torch.load('checkpoints/best_val_loss.pt'))\n",
    "\n",
    "# Run test\n",
    "one_epoch_test(data_loaders['test'], model, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <img src=\"static_images/icons/noun-advance-2109145.png\" alt=\">\" style=\"width:50px\"/> Step 7: Export using torchscript\n",
    "\n",
    "Great job creating your CNN models! Now that you have put in all the hard work of creating accurate classifiers, let's export it so we can use it in our app.\n",
    "\n",
    "But first, as usual, we need to complete some code!\n",
    "\n",
    "Open `src/predictor.py` and fill up the missing code, then run the tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.7, pytest-7.4.0, pluggy-1.0.0 -- C:\\Users\\jblam\\anaconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\jblam\\Downloads\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\\Landmark-Classification-Tagging-for-Social-Media-2.0-main\n",
      "plugins: anyio-4.2.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "src/predictor.py::test_model_construction \u001b[31mFAILED\u001b[0m\u001b[31m                         [100%]\u001b[0m\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________________ test_model_construction ___________________________\u001b[0m\n",
      "\n",
      "data_loaders = {'test': <torch.utils.data.dataloader.DataLoader object at 0x00000113D9808FD0>, 'train': <torch.utils.data.dataloader.DataLoader object at 0x00000113D97D4AD0>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x00000113D9339B10>}\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_model_construction\u001b[39;49;00m(data_loaders):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfrom\u001b[39;49;00m \u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodel\u001b[39;49;00m \u001b[94mimport\u001b[39;49;00m MyModel\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfrom\u001b[39;49;00m \u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mhelpers\u001b[39;49;00m \u001b[94mimport\u001b[39;49;00m compute_mean_and_std\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        mean, std = compute_mean_and_std()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        model = MyModel(num_classes=\u001b[94m3\u001b[39;49;00m, dropout=\u001b[94m0.3\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        dataiter = \u001b[96miter\u001b[39;49;00m(data_loaders[\u001b[33m\"\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      ">       images, labels = dataiter.next()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute 'next'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31msrc\\predictor.py\u001b[0m:93: AttributeError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "Reusing cached mean and std\n",
      "Dataset mean: tensor([0.4638, 0.4725, 0.4687]), std: tensor([0.2697, 0.2706, 0.3017])\n",
      "---------------------------- Captured stdout call -----------------------------\n",
      "Reusing cached mean and std\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m src/predictor.py::\u001b[1mtest_model_construction\u001b[0m - AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute 'n...\n",
      "\u001b[31m============================== \u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 5.77s\u001b[0m\u001b[31m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -vv src/predictor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allright, now we are ready to export our model using our Predictor class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you might need to restart the notebook before running this step\n",
    "# If you get an error about RuntimeError: Can't redefine method: forward on class\n",
    "# restart your notebook then execute only this cell\n",
    "from src.predictor import Predictor\n",
    "from src.helpers import compute_mean_and_std\n",
    "from src.model import MyModel\n",
    "from src.data import get_data_loaders\n",
    "import torch\n",
    "\n",
    "data_loaders = get_data_loaders(batch_size=1)\n",
    "\n",
    "# First let's get the class names from our data loaders\n",
    "class_names = data_loaders[\"train\"].dataset.classes\n",
    "\n",
    "# Then let's move the model_transfer to the CPU\n",
    "# (we don't need GPU for inference)\n",
    "model = MyModel(num_classes=50, dropout=0.5).cpu()\n",
    "\n",
    "# Let's make sure we use the right weights by loading the\n",
    "# best weights we have found during training\n",
    "# NOTE: remember to use map_location='cpu' so the weights\n",
    "# are loaded on the CPU (and not the GPU)\n",
    "\n",
    "model.load_state_dict(torch.load('checkpoints/best_val_loss.pt', map_location=\"cpu\")) # YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Let's wrap our model using the predictor class\n",
    "mean, std = compute_mean_and_std()\n",
    "predictor = Predictor(model, class_names, mean, std).cpu()\n",
    "\n",
    "# Export using torch.jit.script\n",
    "scripted_predictor = torch.jit.script(predictor) # YOUR CODE HERE\n",
    "# scripted_model = torch.jit.script(model)#\n",
    "scripted_predictor.save(\"checkpoints/original_exported.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make sure the exported model has the same performance as the original one, by reloading it and testing it. The Predictor class takes different inputs than the non-wrapped model, so we have to use a specific test loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load using torch.jit.load\n",
    "model_reloaded =  torch.jit.load(\"checkpoints/original_exported.pt\") # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.predictor import predictor_test\n",
    "\n",
    "pred, truth = predictor_test(data_loaders['test'], model_reloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's have a look at the confusion matrix of the model we are going to use in production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helpers import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(pred, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "274ae103f9d3dc58dfa03d8dfb67cc18028596b9d388a03692b74998112c7d29"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
